{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of labels_analysis_object_detection_by_Umme.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "smQWTwI7k4Bf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# General configuration - object detection\n",
        "**Object Detection API configuration**: In this step, the model for object detection is downloaded, also some copying and deletion of references are done to leave the whole scheme configured."
      ]
    },
    {
      "metadata": {
        "id": "XnBVJiIzYune",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n",
        "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
        "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
        "!cp -R models/research/object_detection/ object_detection/\n",
        "!rm -rf models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qwWt0kSihqCv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports \n",
        "\n",
        "**Imports** needed to run the Object Detection API demonstration"
      ]
    },
    {
      "metadata": {
        "id": "YspILW_rZu0v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import cv2\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from scipy.stats import itemfreq\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGx_08UcmtOF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Configuration** of the model to use, path to the frozen inference graph and extra config elements for the Object detection API implementation."
      ]
    },
    {
      "metadata": {
        "id": "8n_alUkLZ1gl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "PATH_TO_LABELS = os.path.join('object_detection/data', 'mscoco_label_map.pbtxt')\n",
        "NUM_CLASSES = 90\n",
        "\n",
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())\n",
        "    \n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r366ydkzxM-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QRa4EOEKm_gW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload tie image"
      ]
    },
    {
      "metadata": {
        "id": "b8xKj6o-7pUJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "019z87nzq8CP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#red tie demo\n",
        "!wget http://www.disfrazjaiak.com/1294-thickbox_default/corbata-roja.jpg -O images/custom_img_1.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y0Dngt6Dd-H0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls ./images/ #optional to validte files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IRmj3EKfk6mr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "test_image = Image.open('./images/custom_img_1.jpg')\n",
        "imshow(test_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rrEF8Vt3iT26",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = 'images'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'custom_img_{}.jpg'.format(i)) for i in range(1, 2) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-z6Mz7p1l3c2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Routine to get labels"
      ]
    },
    {
      "metadata": {
        "id": "NFxyXQEyeYXe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getLabels(boxes,classes, score):\n",
        "      labels = []\n",
        "      for i, box in enumerate(np.squeeze(boxes)):\n",
        "        if(np.squeeze(scores)[i] > score):\n",
        "          labels.append(category_index[np.squeeze(classes)[i]]['name']) \n",
        "        \n",
        "      return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oTh0seTUl4aD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Objects Analysis into Image"
      ]
    },
    {
      "metadata": {
        "id": "RtcqhVwm9-U4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with detection_graph.as_default():\n",
        "  with tf.Session(graph=detection_graph) as sess:\n",
        "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "    for image_path in TEST_IMAGE_PATHS:\n",
        "      image = Image.open(image_path)\n",
        "      image_np = load_image_into_numpy_array(image)\n",
        "      \n",
        "      \n",
        "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "      (boxes, scores, classes, num) = sess.run(\n",
        "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "     \n",
        "      print(image_path)\n",
        "      print(getLabels(boxes, classes, 0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dVhrBSEHrSlA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optional CV [video or cam]"
      ]
    },
    {
      "metadata": {
        "id": "WVu9fvCtF_zJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjzkcu1BtptO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir videos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3x8B5Su_tkPP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/videostestingobjectdetection/video_demo_baby_dog.mp4 -O videos/video_demo_baby_dog.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AWJCdC6krVE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out = cv2.VideoWriter('outputtestvideojapanstreet.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, (960,540))\n",
        "\n",
        "filename = 'videos/testvideojapanstreet.mp4'\n",
        "cap = cv2.VideoCapture(filename)\n",
        "\n",
        "with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "        counter = 0\n",
        "        while (True):\n",
        "            ret, image_np = cap.read()\n",
        "            \n",
        "            counter += 1\n",
        "            if ret:\n",
        "              h = image_np.shape[0]\n",
        "              w = image_np.shape[1]\n",
        "\n",
        "              if counter % 1 == 0:\n",
        "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "                boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "                scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "                classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "                (boxes, scores, classes, num_detections) = sess.run(\n",
        "                    [boxes, scores, classes, num_detections],\n",
        "                    feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "                vis_util.visualize_boxes_and_labels_on_image_array(image_np,\n",
        "                                                                     np.squeeze(boxes),\n",
        "                                                                     np.squeeze(classes).astype(np.int32),\n",
        "                                                                     np.squeeze(scores),\n",
        "                                                                     category_index,\n",
        "                                                                     use_normalized_coordinates=True,\n",
        "                                                                     line_thickness=0,\n",
        "                                                                     min_score_thresh=0.3)\n",
        "\n",
        "              out.write(image_np)\n",
        "            else:\n",
        "              break\n",
        "out.release()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "odRnWqizywaW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0mcD4ApaIkZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1HxW4YZQIsCI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from moviepy.editor import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hg_jtOLqIO0s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clip = VideoFileClip(\"outputtestvideojapanstreet.avi\")\n",
        "clip.write_videofile(\"outputtestvideojapanstreet.mp4\", codec='libx264')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAbfEIcpITAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BdkVzUPL0hxD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4VRsP-YqxuqA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "video = io.open('videos/testvideojapanstreet.mp4', 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "HTML(data='''<video width=\"80%\" alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7fFkzvKuygMP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "video = io.open('outputtestvideojapanstreet.mp4', 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "HTML(data='''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QEBzxveFfoaz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Video processing using moviepy [alternative -options]"
      ]
    },
    {
      "metadata": {
        "id": "FnINNTqWexhf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    with detection_graph.as_default():\n",
        "        with tf.Session(graph=detection_graph) as sess:\n",
        "            image_process = detect_objects(image, sess, detection_graph)\n",
        "            return image_process"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64Vz79DSfY8e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def detect_objects(image_np, sess, detection_graph):\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "    (boxes, scores, classes, num_detections) = sess.run(\n",
        "        [boxes, scores, classes, num_detections],\n",
        "        feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        np.squeeze(boxes),\n",
        "        np.squeeze(classes).astype(np.int32),\n",
        "        np.squeeze(scores),\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    return image_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6z2xapNge4cP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "white_output = 'output.mp4'\n",
        "clip1 = VideoFileClip(\"videos/video_demo_baby_dog.mp4\")\n",
        "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!s\n",
        "%time white_clip.write_videofile(white_output, audio=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}